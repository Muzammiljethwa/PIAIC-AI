{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = r.get(\"https://ask.piaic.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(web.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = [],[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping All Categories Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for i in soup.find_all(\"a\",class_=\"qa-nav-cat-link\"):\n",
    "    i = \"https://ask.piaic.org/\"+i['href']\n",
    "    pages.append(i.replace(\"./\",\"\"))\n",
    "pages.remove(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = [\"4ir\",\"general\",\"AI\",\"android\",'blockchain','cloud-native',\n",
    "        \"Git\",\"iot\",\"ios\",\"web\"]\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    0 : '4ir',\n",
    "    1 : 'general',\n",
    "    2 : 'AI',\n",
    "    3 : 'android',\n",
    "    4 : 'blockchain',\n",
    "    5 : 'cloud-native',\n",
    "    6 : 'Git',\n",
    "    7 : 'iot',\n",
    "    8 : 'ios',\n",
    "    9 : 'web'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Questions and Labels from all Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in pages:\n",
    "    \n",
    "    page = r.get(i)\n",
    "    soup = bs(page.text,\"html.parser\")\n",
    "    \n",
    "    questions = []\n",
    "    for i in soup.find_all(\"div\",class_='qa-q-item-title'):\n",
    "        questions.append(i.getText().replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "        x.append(i.getText().replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "        \n",
    "    for i in range(len(questions)):\n",
    "        y.append(label[k])\n",
    "    \n",
    "    k=k+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 262)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Labels Into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in y:\n",
    "    if i == '4ir':\n",
    "        l.append(0)\n",
    "    elif i == 'general':\n",
    "        l.append(1)\n",
    "    elif i == 'AI':\n",
    "        l.append(2)\n",
    "    elif i == 'android':\n",
    "        l.append(3)\n",
    "    elif i == 'blockchain':\n",
    "        l.append(4)\n",
    "    elif i == 'cloud-native':\n",
    "        l.append(5)\n",
    "    elif i == 'Git':\n",
    "        l.append(6)\n",
    "    elif i == 'iot':\n",
    "        l.append(7)\n",
    "    elif i == 'ios':\n",
    "        l.append(8)\n",
    "    elif i == 'web':\n",
    "        l.append(9)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Questions\":x,\"Label\":l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 262)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Data Frame and Saving Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Passing Markes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>PIAIC KA 2nd online videos kab post hogi? onsi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>How come DVCS not heavy on the comp?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>question regarding ch4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>safe browser is not showing my course</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Questions  Label\n",
       "175                                     Passing Markes      5\n",
       "122  PIAIC KA 2nd online videos kab post hogi? onsi...      2\n",
       "206               How come DVCS not heavy on the comp?      6\n",
       "234                             question regarding ch4      7\n",
       "88               safe browser is not showing my course      2"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "df.to_csv(\"Ask_PIAIC.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[0:,0]\n",
    "y = df.iloc[0:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing  and One Hot Encoding Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 627 unique tokens.\n",
      "1st sentence(one hot encoded):\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(x, mode='binary')\n",
    "print(\"1st sentence(one hot encoded):\\n\",one_hot_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.asarray(y)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 6 7 2 5 2 4 4 7 0 6 0 6 0 7 7 0 6 4 7 2 6 6 4 2 1 1 4 5 2 1 7 2 7 0 7\n",
      " 1 7 2 4 7 7 4 6 1 5 1 2 4 1 2 1 4 0 5 1 2 7 2 5 4 7 1 2 0 2 1 2 1 5 6 4 7\n",
      " 1 4 7 1 0 4 7 5 7 7 7 1 4 1 2 2 7 4 2 1 2 4 4 5 5 4 5 4 7 1 2 0 2 7 7 4 0\n",
      " 0 7 2 1 2 7 1 7 4 4 0 2 8 4 7 4 2 2 2 4 6 1 4 1 1 1 1 5 0 7 7 1 1 4 1 2 7\n",
      " 2 1 1 1 1 4 6 2 5 7 0 2 1 7 1 5 7 7 4 1 1 0 0 7 1 2 1 0 0 7 2 1 9 7 1 4 5\n",
      " 4 5 2 4 7 5 4 1 4 7 7 1 2 0 6 0 5 4 4 2 5 7 2 1 4 7 1 4 2 0 7 2 5 4 7 7 2\n",
      " 4 4 1 1 7 4 4 5 9 7 7 1 4 1 7 2 4 7 9 1 2 4 2 2 2 5 1 0 2 2 4 0 4 0 2 4 2\n",
      " 0 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "encoded = to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 10)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, y_train = one_hot_results,encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262, 628), (262, 10))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 262 samples\n",
      "Epoch 1/20\n",
      "262/262 [==============================] - 4s 14ms/sample - loss: 8.5979 - acc: 0.1908\n",
      "Epoch 2/20\n",
      "262/262 [==============================] - 2s 8ms/sample - loss: 6.0381 - acc: 0.1908\n",
      "Epoch 3/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.8128 - acc: 0.1832\n",
      "Epoch 4/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.8083 - acc: 0.1794\n",
      "Epoch 5/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5950 - acc: 0.1794\n",
      "Epoch 6/20\n",
      "262/262 [==============================] - 2s 6ms/sample - loss: 4.5772 - acc: 0.2214\n",
      "Epoch 7/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.6276 - acc: 0.1985\n",
      "Epoch 8/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.6079 - acc: 0.1985\n",
      "Epoch 9/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5907 - acc: 0.1985\n",
      "Epoch 10/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5714 - acc: 0.2099\n",
      "Epoch 11/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5534 - acc: 0.1985\n",
      "Epoch 12/20\n",
      "262/262 [==============================] - 2s 6ms/sample - loss: 4.5580 - acc: 0.2023\n",
      "Epoch 13/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5514 - acc: 0.1870\n",
      "Epoch 14/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5488 - acc: 0.1718\n",
      "Epoch 15/20\n",
      "262/262 [==============================] - 2s 8ms/sample - loss: 4.5420 - acc: 0.1794\n",
      "Epoch 16/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5363 - acc: 0.1870\n",
      "Epoch 17/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5291 - acc: 0.1832\n",
      "Epoch 18/20\n",
      "262/262 [==============================] - 2s 6ms/sample - loss: 4.5198 - acc: 0.1985\n",
      "Epoch 19/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5127 - acc: 0.1870\n",
      "Epoch 20/20\n",
      "262/262 [==============================] - 2s 7ms/sample - loss: 4.5511 - acc: 0.1985\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(16))\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(input_train, y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Ask_PIAIC.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = r.get(\"https://ask.piaic.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(web.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for i in soup.find_all(\"div\",class_='qa-q-item-title'):\n",
    "    questions.append(i.getText().replace(\"\\n\",\"\").replace(\"\\t\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Questions from Data Tokenizer and Predicting Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(li):\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(li)\n",
    "    one_hot_results = tokenizer.texts_to_matrix(li, mode='binary')\n",
    "    prediction = model.predict(one_hot_results)\n",
    "\n",
    "    a,d=0,0\n",
    "    for i in prediction[0]:\n",
    "        if float(i)>a or float(i)==a:\n",
    "            a=i\n",
    "            d=0\n",
    "        elif float(i)<a:\n",
    "            d=d+1\n",
    "    index = len(prediction[0])-d-1\n",
    "    \n",
    "    print(f'{li} : {names[index]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why do we need CBBF certoificate? : AI\n",
      "B3 Q2 rust quiz but lecture not upload : blockchain\n",
      "Watch videos on portal not on youtube? : AI\n",
      "Can i deposit fee before certification? : blockchain\n",
      "How can I withdraw or freeze a course? : blockchain\n",
      "Voucher Generation mail : blockchain\n",
      "Git classes : blockchain\n",
      "necessary install node.js : blockchain\n",
      "Diff btw a Smrt contract and OOP class? : blockchain\n",
      "Passing Markes : blockchain\n",
      "Announcement section : AI\n",
      "Flexibility in viewing video lectures : blockchain\n",
      "Build aiinyourcompany,aiandsocietycover? : blockchain\n",
      "Explain Scarcity? : blockchain\n",
      "blockchain business foundation exam? : blockchain\n",
      "Difference b/w slack, telegm & fb groups : blockchain\n",
      "mobile web : blockchain\n",
      "what is scope of blockchain in pakistan? : AI\n",
      "I have a few questions : blockchain\n",
      "less than 50% in Q2 : blockchain\n",
      "how to install global surge in ubuntu : blockchain\n",
      "docker documentation : blockchain\n",
      "struct Vs enum : blockchain\n",
      "Haven't received key for AIC Quiz 2 : blockchain\n",
      "Install only linux : blockchain\n",
      "github desktop : blockchain\n",
      "final exam : blockchain\n",
      "Quiz not available to attempt : blockchain\n",
      "Iot quiz 2 unavailable : blockchain\n",
      "if quiz not attempt on time : blockchain\n",
      "What does --release flag do : AI\n",
      "constant & immutable variable : blockchain\n",
      "#[derive(Debug)] : blockchain\n",
      "Panic VS Compile Time Error : blockchain\n",
      "Block Mining : blockchain\n",
      "How to write println. : blockchain\n",
      "use of iter() : blockchain\n",
      "Public keys : blockchain\n",
      "Private key : blockchain\n",
      "Quiz 2 key : blockchain\n",
      "stuck in linux installation : blockchain\n",
      "RUST - PARTIAL MOVE error : blockchain\n",
      "I am facing this error ??? : blockchain\n",
      "From where we can get Our Assignment : blockchain\n",
      "Rust variables : blockchain\n",
      "Giving error in creating Cargo new : blockchain\n",
      "difference between function & method? : blockchain\n",
      "how to get user input as bool. : blockchain\n",
      "Q2 Promoted : blockchain\n",
      ".trim command : blockchain\n"
     ]
    }
   ],
   "source": [
    "for i in questions:\n",
    "    check(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
